{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 1 PART 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0: Load Packages and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Sentence 1: Under the trust 's Fit for the Future proposals , two of the hospitals would lose their A&E units with consultant - led maternity services also possibly being centralised on one site .\n",
      "Train Sentence 2: Man charged over drugs seizure\n",
      "Train Sentence 3: Borrowing from your 401 ( k ) or withdrawing from your IRA , on the other hand , can make sense in some situations , says Michael Chasnoff , a financial planner in Cincinnati : \" If going back to school helps you command a higher level of income , there is a return on your investment . \"\n",
      "Train Sentence 4: It was the first rate cut in more than four years .\n",
      "Train Sentence 5: Yes , Schieffer is excellent , \" he said .\n",
      "\n",
      "Test Sentence 1: Before the movie started , with co - stars Matthew Broderick , Chris Rock , and Renee Zellweger in attendance , Seinfeld did a little stand up for the audience just to warm \" em up .\n",
      "Test Sentence 2: If you have owned the property for more than three years , you can apply for \" taper relief , \" by which you can reduce any taxable gain by 5% for each year of ownership , up to a maximum 40% .\n",
      "Test Sentence 3: The road was pitted with tank treads .\n",
      "Test Sentence 4: But the drama has attracted attention in the US largely because of the character 's many sexual trysts .\n",
      "Test Sentence 5: Global truck makers are keen for a larger share of India 's market , the fifth - biggest in the world , and expected to expand on improving infrastructure and new safety and emission rules .\n"
     ]
    }
   ],
   "source": [
    "# Load Train and Test\n",
    "\n",
    "# Load the train.txt file\n",
    "with open('train.txt', 'r', encoding='utf-8') as train_file:\n",
    "    train_sentences = [line.strip() for line in train_file.readlines()]\n",
    "\n",
    "# Load the test.txt file\n",
    "with open('test.txt', 'r', encoding='utf-8') as test_file:\n",
    "    test_sentences = [line.strip() for line in test_file.readlines()]\n",
    "\n",
    "# Test if we loaded sentences properly\n",
    "for i in range(5):\n",
    "    print(f\"Train Sentence {i+1}: {train_sentences[i]}\")\n",
    "    \n",
    "print()\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Test Sentence {i+1}: {test_sentences[i]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Pad each sentence in the training and test corpora with start and end symbols (you can use &lt;s&gt; and &lt;/s&gt;, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Train Sentence 1: <s> Under the trust 's Fit for the Future proposals , two of the hospitals would lose their A&E units with consultant - led maternity services also possibly being centralised on one site . </s>\n",
      "Padded Train Sentence 2: <s> Man charged over drugs seizure </s>\n",
      "Padded Train Sentence 3: <s> Borrowing from your 401 ( k ) or withdrawing from your IRA , on the other hand , can make sense in some situations , says Michael Chasnoff , a financial planner in Cincinnati : \" If going back to school helps you command a higher level of income , there is a return on your investment . \" </s>\n",
      "Padded Train Sentence 4: <s> It was the first rate cut in more than four years . </s>\n",
      "Padded Train Sentence 5: <s> Yes , Schieffer is excellent , \" he said . </s>\n",
      "\n",
      "Padded Test Sentence 1: <s> Before the movie started , with co - stars Matthew Broderick , Chris Rock , and Renee Zellweger in attendance , Seinfeld did a little stand up for the audience just to warm \" em up . </s>\n",
      "Padded Test Sentence 2: <s> If you have owned the property for more than three years , you can apply for \" taper relief , \" by which you can reduce any taxable gain by 5% for each year of ownership , up to a maximum 40% . </s>\n",
      "Padded Test Sentence 3: <s> The road was pitted with tank treads . </s>\n",
      "Padded Test Sentence 4: <s> But the drama has attracted attention in the US largely because of the character 's many sexual trysts . </s>\n",
      "Padded Test Sentence 5: <s> Global truck makers are keen for a larger share of India 's market , the fifth - biggest in the world , and expected to expand on improving infrastructure and new safety and emission rules . </s>\n"
     ]
    }
   ],
   "source": [
    "padded_train_sentences = train_sentences\n",
    "padded_test_sentences = test_sentences\n",
    "\n",
    "# Iterate over each sentence using a range based for loop as strings are immutable, hence we have to overwrite indeces\n",
    "for i in range(len(padded_train_sentences)):\n",
    "    padded_train_sentences[i] = \"<s> \" + padded_train_sentences[i] + \" </s>\"\n",
    "\n",
    "for i in range(len(padded_test_sentences)):\n",
    "    padded_test_sentences[i] = \"<s> \" + padded_test_sentences[i] + \" </s>\"\n",
    "\n",
    "\n",
    "# Test if we padded our sentences properly\n",
    "for i in range(5):\n",
    "    print(f\"Padded Train Sentence {i+1}: {padded_train_sentences[i]}\")\n",
    "    \n",
    "print()\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Padded Test Sentence {i+1}: {padded_test_sentences[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lowercase all words in the training and test corpora. Note that the data already has been tokenized (i.e. the punctuation has been split off words).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowered Train Sentence 1: <s> under the trust 's fit for the future proposals , two of the hospitals would lose their a&e units with consultant - led maternity services also possibly being centralised on one site . </s>\n",
      "Lowered Train Sentence 2: <s> man charged over drugs seizure </s>\n",
      "Lowered Train Sentence 3: <s> borrowing from your 401 ( k ) or withdrawing from your ira , on the other hand , can make sense in some situations , says michael chasnoff , a financial planner in cincinnati : \" if going back to school helps you command a higher level of income , there is a return on your investment . \" </s>\n",
      "Lowered Train Sentence 4: <s> it was the first rate cut in more than four years . </s>\n",
      "Lowered Train Sentence 5: <s> yes , schieffer is excellent , \" he said . </s>\n",
      "\n",
      "Lowered Test Sentence 1: <s> before the movie started , with co - stars matthew broderick , chris rock , and renee zellweger in attendance , seinfeld did a little stand up for the audience just to warm \" em up . </s>\n",
      "Lowered Test Sentence 2: <s> if you have owned the property for more than three years , you can apply for \" taper relief , \" by which you can reduce any taxable gain by 5% for each year of ownership , up to a maximum 40% . </s>\n",
      "Lowered Test Sentence 3: <s> the road was pitted with tank treads . </s>\n",
      "Lowered Test Sentence 4: <s> but the drama has attracted attention in the us largely because of the character 's many sexual trysts . </s>\n",
      "Lowered Test Sentence 5: <s> global truck makers are keen for a larger share of india 's market , the fifth - biggest in the world , and expected to expand on improving infrastructure and new safety and emission rules . </s>\n"
     ]
    }
   ],
   "source": [
    "lowered_padded_train_sentences = train_sentences\n",
    "lowered_padded_test_sentences = test_sentences\n",
    "\n",
    "for i in range(len(lowered_padded_train_sentences)):\n",
    "    lowered_padded_train_sentences[i] = padded_train_sentences[i].lower() \n",
    "\n",
    "for i in range(len(lowered_padded_test_sentences)):\n",
    "    lowered_padded_test_sentences[i] = lowered_padded_test_sentences[i].lower() \n",
    "\n",
    "# Test if we lowered sentences properly\n",
    "for i in range(5):\n",
    "    print(f\"Lowered Train Sentence {i+1}: {lowered_padded_train_sentences[i]}\")\n",
    "    \n",
    "print()\n",
    "\n",
    "for i in range(5):\n",
    "    print(f\"Lowered Test Sentence {i+1}: {lowered_padded_test_sentences[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace all words occurring in the training data once with the token &lt;unk&gt; and &lt;/unk&gt;. Every word in the test data not seen in training should be treated as &lt;unk&gt;.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Obtained ...\n"
     ]
    }
   ],
   "source": [
    "# Obtain Vocabulary | List of unique tokens  \n",
    "\n",
    "vocabulary = set()      # Using a set reduces the complexity into 0(n + m) rather than 0(n^2) as there is no need to check for membership of the token since sets handle duplicates\n",
    "\n",
    "for sentence in lowered_padded_train_sentences:\n",
    "    tokens = sentence.split()\n",
    "    \n",
    "    for token in tokens:\n",
    "        vocabulary.add(token)\n",
    "\n",
    "\n",
    "vocabulary = list(vocabulary)\n",
    "\n",
    "print(f\"Vocabulary Obtained ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 83045\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(vocabulary)\n",
    "print(f\"Vocabulary size: {vocabulary_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies counted ...\n"
     ]
    }
   ],
   "source": [
    "# Counting frequency of all tokens \n",
    "frequency_count = {}\n",
    "\n",
    "for sentence in lowered_padded_train_sentences:\n",
    "    tokens = sentence.split()\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in frequency_count:\n",
    "            frequency_count[token] += 1\n",
    "        else:\n",
    "            frequency_count[token] = 1\n",
    "\n",
    "# for token in vocabulary:\n",
    "#     print(f\"{str(token).ljust(20)} : {frequency_count[token]}\")\n",
    "\n",
    "print(\"Frequencies counted ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 2568210 tokens.\n"
     ]
    }
   ],
   "source": [
    "corpus_size = 0\n",
    "\n",
    "for token in frequency_count:\n",
    "    corpus_size += frequency_count[token]\n",
    "\n",
    "print(f\"There are a total of {corpus_size} tokens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens that only appeared once accounted for ...\n"
     ]
    }
   ],
   "source": [
    "# Identify words that occured only once and change value to the uknown token\n",
    "tokens_that_appeared_only_once = []\n",
    "\n",
    "for token in frequency_count:\n",
    "    if frequency_count[token] <= 1:\n",
    "        tokens_that_appeared_only_once.append(token)\n",
    "\n",
    "#print(tokens_that_appeared_only_once)\n",
    "print(\"Tokens that only appeared once accounted for ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41307 tokens that appeared only once or less\n"
     ]
    }
   ],
   "source": [
    "number_of_tokens_that_appeared_only_once = len(tokens_that_appeared_only_once)\n",
    "print(f\"There are {number_of_tokens_that_appeared_only_once} tokens that appeared only once or less\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all tokens that appeared only once with <unk>\n",
    "processed_train_sentences = lowered_padded_train_sentences\n",
    "\n",
    "for sentence in processed_train_sentences:\n",
    "    tokens = sentence.split()\n",
    "\n",
    "    # Declare an empty list to hold the processed tokens\n",
    "    processed_tokens = []\n",
    "\n",
    "    # Iterate over each toekn in the sentence \n",
    "    for token in tokens:\n",
    "\n",
    "        if token in tokens_that_appeared_only_once:\n",
    "            processed_tokens.append(\"<unk>\")\n",
    "        else:\n",
    "            processed_tokens.append(token)\n",
    "\n",
    "print(\"Processed sentences ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "tokens_that_appeared_only_once == unk_count? False\n"
     ]
    }
   ],
   "source": [
    "# Verify that you replaced all the tokens that appearaed only once with the unkown token.\n",
    "\n",
    "unk_count = 0\n",
    "\n",
    "for sentence in processed_train_sentences:\n",
    "    sentence = sentence.split()\n",
    "    \n",
    "    for token in sentence:\n",
    "\n",
    "        if token == \"<unk>\":\n",
    "            unk_count += 1\n",
    "\n",
    "\n",
    "print(unk_count)\n",
    "print(f\"tokens_that_appeared_only_once == unk_count? {tokens_that_appeared_only_once == unk_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions: \n",
    "1. Should we actually replace all words occuring once with <- unk -> token in the original corpus? Then wouldn't the count for this token be large? Or shall we just modify the frequency count by removing all the ones that only occur once?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
